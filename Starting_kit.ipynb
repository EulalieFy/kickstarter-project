{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 1, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu(first_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.spatial import distance\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from problem import get_train_data, get_test_data\n",
    "from problem import metric_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../kickstarter-bis/data/test.csv')\n",
    "data = data.dropna(subset=['name'])\n",
    "\n",
    "data.index = np.arange(0, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do before in the \"problem.py\"\n",
    "\n",
    "labels = data['pledged']\n",
    "data.drop(['pledged', 'state', 'usd_pledged_real', 'pledged', 'usd pledged', 'backers'], \n",
    "          axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3)\n",
    "\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dashes and apostrophes from punctuation marks \n",
    "punct = string.punctuation.replace('-', '').replace(\"'\",'')\n",
    "# regex to match intra-word dashes and intra-word apostrophes\n",
    "my_regex = re.compile(r\"(\\b[-']\\b)|[\\W_]\")\n",
    "\n",
    "def clean_string(string, punct=punct, my_regex=my_regex, to_lower=False):\n",
    "    if to_lower:\n",
    "        string = string.lower()\n",
    "    # remove formatting\n",
    "    str = re.sub('\\s+', ' ', string)\n",
    "     # remove punctuation\n",
    "    str = ''.join(l for l in str if l not in punct)\n",
    "    # remove dashes that are not intra-word\n",
    "    str = my_regex.sub(lambda x: (x.group(1) if x.group(1) else ' '), str)\n",
    "    # strip extra white space\n",
    "    str = re.sub(' +',' ',str)\n",
    "    # strip leading and trailing white space\n",
    "    str = str.strip()\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #### NLP BASICS ####\n",
    "        names = X['name'].tolist()\n",
    "        cleaned_project_names = []\n",
    "        \n",
    "        for idx, doc in enumerate(names):\n",
    "            # clean\n",
    "            doc = clean_string(doc, punct, my_regex, to_lower=True)\n",
    "            # tokenize (split based on whitespace)\n",
    "            tokens = doc.split(' ')\n",
    "            # remove digits\n",
    "            tokens = [''.join([elt for elt in token if not elt.isdigit()]) for token in tokens]\n",
    "            # remove tokens shorter than 3 characters in size\n",
    "            tokens = [token for token in tokens if len(token) > 1]\n",
    "            # remove tokens exceeding 25 characters in size\n",
    "            tokens = [token for token in tokens if len(token) <= 25]\n",
    "            cleaned_project_names.append(tokens)\n",
    "            \n",
    "        ##### Word2vect embedding\n",
    "        self.model = Word2Vec(cleaned_project_names, min_count=1, size=100, workers=8)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        \n",
    "        #### SIMPLE TRANSFORMATION #### \n",
    "        \n",
    "        data['launched_date'] = pd.to_datetime(data['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "        data['deadline_date'] = pd.to_datetime(data['deadline'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Length of project\n",
    "        data['length'] = data['deadline_date'] - data['launched_date']\n",
    "        data['length'] = [d.days for d in data['length']]\n",
    "        \n",
    "        # Features with month and year of launch\n",
    "        data['year'] = [d.year for d in data['launched_date']]\n",
    "        data['month'] = [d.month for d in data['launched_date']]\n",
    "        data['day'] = [d.day for d in data['launched_date']]\n",
    "        \n",
    "        # Length of name\n",
    "        data['name_length'] = [len(name) for name in data['name']]\n",
    "\n",
    "        # Number of words\n",
    "        data['word_number'] = [len(name.split(' ')) for name in data['name']]\n",
    "\n",
    "        # Ponctuation\n",
    "        data['question'] = (data.name.str[-1] == '?').astype(int)\n",
    "        data['exclamation'] = (data.name.str[-1] == '!').astype(int)\n",
    "\n",
    "        # Upper\n",
    "        data['uppercase'] = data.name.str.isupper().astype(float)\n",
    "        \n",
    "        # Create dummies for categorical features\n",
    "        main_category = pd.get_dummies(data['main_category'],prefix='mc')\n",
    "        category = pd.get_dummies(data['category'], prefix = 'cat')\n",
    "        country = pd.get_dummies(data['country'], prefix = 'country')\n",
    "        currency = pd.get_dummies(data['currency'], prefix = 'currency')\n",
    "\n",
    "        data = pd.concat([data, main_category, category, country, currency], axis=1)\n",
    "        \n",
    "        # Drop several features\n",
    "        names = data['name'].tolist()\n",
    "\n",
    "        features_to_drop =['main_category', 'category', 'country', 'currency', 'name',\n",
    "                           'deadline', 'deadline_date', 'launched_date', 'launched',\n",
    "                           'usd_goal_real', 'ID']\n",
    "        data.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        #### NLP BASICS ####\n",
    "        cleaned_project_names = []\n",
    "        \n",
    "        for idx, doc in enumerate(names):\n",
    "            # clean\n",
    "            doc = clean_string(doc, punct, my_regex, to_lower=True)\n",
    "            # tokenize (split based on whitespace)\n",
    "            tokens = doc.split(' ')\n",
    "            # remove digits\n",
    "            tokens = [''.join([elt for elt in token if not elt.isdigit()]) for token in tokens]\n",
    "            # remove tokens shorter than 3 characters in size\n",
    "            tokens = [token for token in tokens if len(token) > 1]\n",
    "            # remove tokens exceeding 25 characters in size\n",
    "            tokens = [token for token in tokens if len(token) <= 25]\n",
    "            cleaned_project_names.append(tokens)\n",
    "            \n",
    "        name_matrix = np.zeros((len(cleaned_project_names), 100), dtype=\"float32\")\n",
    "\n",
    "        for i in range(len(cleaned_project_names)):\n",
    "            try:\n",
    "                name_matrix[i,]= self.model.wv[cleaned_project_names[i]].sum(0) / len(cleaned_project_names[i]) \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        name_embeddings = pd.DataFrame(name_matrix)\n",
    "        \n",
    "        data = pd.concat([data, name_embeddings], axis=1)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = LGBMRegressor()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.maximum(prediction, np.zeros(prediction.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "feature_extractor.fit(X_train, y_train)\n",
    "\n",
    "X_train = feature_extractor.transform(X_train)\n",
    "X_test = feature_extractor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_regressor = Regressor()\n",
    "\n",
    "lgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- REGRESSION METRICS --------\n",
      "\n",
      "RMSE: 78447.00\n",
      "MAE: 13146.39\n",
      "\n",
      "-------- CLASSIFICATION METRICS --------\n",
      "\n",
      "Accuracy: 0.65\n",
      "Precision: 0.49\n",
      "Recall: 0.39\n"
     ]
    }
   ],
   "source": [
    "metric_report(X_test, y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
