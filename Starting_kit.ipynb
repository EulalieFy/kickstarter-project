{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataCamp Business Case - Kickstarter - Predicting success of fundraising\n",
    "\n",
    "### Authors : Hamza Filali Baba - Eulalie Formery - Damien Grasset - Alice Guichenez - Hugo Perrin\n",
    "\n",
    "M2 DataScience - Université ParisScalay\n",
    " \n",
    "Professors: Alexandre GRAMFORT & Balazs KEGL\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a style=\"color:#00925B\"> 1. Business case</a>\n",
    "\n",
    "- Context\n",
    "- Business problem\n",
    "- Data presentation\n",
    "- Limits of our approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a style=\"color:#00925B\"> 2. Exporation of the data</a>\n",
    "\n",
    "- a completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a style=\"color:#00925B\"> 3. </a>\n",
    "\n",
    "- a completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a style=\"color:#00925B\"> 1. Business case </a>\n",
    "\n",
    "##  <span style=\"color:#00925B\"> 1.1 Context  </span> \n",
    " \n",
    "Kickstarter is one of the world’s largest crowdfunding platforms for gathering money from the public. It is mainly focused on creativity-related projects, in particular in art, music and design. It helps creators to find the resources and support they need to make their projects come real. Kickstarter is a huge global community; 16 million people have brought their contribution to over 150,000 successful projects all over the world. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:#00925B\"> 1.2 Business problem  </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Funding model**\n",
    " \n",
    "The platform is based on an all or nothing funding model: project creators choose a deadline and a minimum funding goal, and money is collected only if the project reaches its goal by the deadline. It is a kind of insurance contract. The funding goal is chosen by the project kicker at the beginning and cannot be changed once the project has been launched. Whenever a project reaches the stated goal, the platform takes a 5% fee on the total amount of money collected. When a project fails, the platform does not gain anything. Therefore, it is to the benefit of Kickstarter that most projects are successful in reaching their funding goal by the deadline. Unlike many other platforms for fundraising and investment, Kickstarter claims no ownership over the projects and the work they produce – their profit is entirely based on the 5% fee they receive in case of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding**\n",
    "\n",
    "There is currently a 36.63% overall rate of success, with some categories performing especially well (almost 62% for dance projects) and others particularly poorly (26% only for fashion). The failure rate is 52.6% and the rest of the projects are canceled or suspended. Mettre un camembert avec les categories et les taux de réussite. Our goal is to increase this rate of success based on the finding that some projects are more meant to success than others. Mettre autres stats genre selon longueur de la deadline, total amount etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business objective**\n",
    "\n",
    "Kickstarter will make most money when most projects come to a success. Our objective is therefore to increase the chances of success of the projects by finding the relevant characteristics that will make them most likely to meet the goal by the deadline. By predicting whether a goal will be reached given a certain project, a certain funding target and a certain deadline, we should help fundraisers to pick adequate attributes and increase the rate of success, which should in turn increase Kickstarter’s profit. In this context, the key performance indicator that should be increased by good predictions is the rate of success – the percentage of projects that actually reach their goal by the deadline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Users of our solution**\n",
    "\n",
    "We could sell our solution to Kickstarter and imagine that they would include a kind of recommendation tool in their app, where fundraisers could input the attributes of their project and Kickstarter would provide them guidance to pick the best characteristics given the output probability of success. Project kickers would benefit from a personalized recommendation and accompaniment and Kickstarter would increase its chances to get the 5% fee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction task**\n",
    "\n",
    "Our database is composed of projects along with a short description, their deadlines, their funding target and the actual funds raised. The goal is to predict among new projects which ones will have highest chances of being successful. It is therefore a **binary classification task** – success or not. The result would lead to an ability to provide advice for a better design of the projects, increasing their chances of meeting the target amount by the deadline. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits of a machine learning solution**\n",
    "\n",
    "A machine learning solution is particularly relevant in this context where we can exploit the huge amount of available data to help the business flourish. It makes it possible to emphasize which characteristics would be better suited for each project, it gives the possibility to Kickstarter to provide a personalized accompaniment for the design of fundraising projects and therefore increases the added value of the app by offering an additional service. All in all, it increases the fees gathered by Kickstarter by increasing the rate of success.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business metrics**\n",
    "\n",
    "A COMPLETER\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow**\n",
    "\n",
    "A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evolution of our solution in time** \n",
    "\n",
    "As new projects are launched, new data becomes available and our model can be improved by benefitting from this increased availability. Furthermore, it could also learn from its past mistakes and successes by evolving as the projects turn out to be failures or successes in accordance with or contrary to the predictions. Consequently, the model will have to be retrained on a regular basis – say once every two months, and this retraining could be based on online learning methods to make it as effective as possible. This would imply additional costs but also increased performance and accuracy for a thriving business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:#00925B\"> 1.3 Data presentation  </span> \n",
    "\n",
    "The data comes from a scrapping of Kickstarter platform (https://www.kickstarter.com)which we got on this page (https://www.kaggle.com/kemical/kickstarter-projects/home).\n",
    "Nb of lignes, stat des etc+ rep à la question What data cleaning/tidying steps were required to obtain clean training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:#00925B\"> 1.4 Limits of our approach  </span> \n",
    "\n",
    "A first limit of our approach comes from the fact that the data we got is probably not enough to explain the successful aspect of the fundraising all by itself. Further data including detailed project description and information about the project kicker (how many projects they already launched and how many of them were successful, host country of the project, etc) would certainly have been useful. \n",
    "Another limit is that we only know if the projects are successful in the sense that the money has been collected or not. However, this should not be the only point of focus because it does not guarantee that once the funds have been collected, the project will be properly implemented: for example, if our model recommends lowering the target amount to get higher chances to collect the money, maybe this amount will underestimate the actual requirements of the project and it will not be realizable. Our point of view was to focus on the profit aspect of the business, but the success of the project once the money has been collected might be relevant to Kickstarter’s business as well. The ideal would have been to have further data about the success of the realization of the project itself and not of the collection of the funds only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 1, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu(first_level=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from scipy.spatial import distance\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.spatial import distance\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "from problem import get_train_data, get_test_data\n",
    "from problem import metric_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../kickstarter-bis/data/test.csv')\n",
    "data = data.dropna(subset=['name'])\n",
    "\n",
    "data.index = np.arange(0, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To do before in the \"problem.py\"\n",
    "\n",
    "labels = data['pledged']\n",
    "data.drop(['pledged', 'state', 'usd_pledged_real', 'pledged', 'usd pledged', 'backers'], \n",
    "          axis=1, inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3)\n",
    "\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dashes and apostrophes from punctuation marks \n",
    "punct = string.punctuation.replace('-', '').replace(\"'\",'')\n",
    "# regex to match intra-word dashes and intra-word apostrophes\n",
    "my_regex = re.compile(r\"(\\b[-']\\b)|[\\W_]\")\n",
    "\n",
    "def clean_string(string, punct=punct, my_regex=my_regex, to_lower=False):\n",
    "    if to_lower:\n",
    "        string = string.lower()\n",
    "    # remove formatting\n",
    "    str = re.sub('\\s+', ' ', string)\n",
    "     # remove punctuation\n",
    "    str = ''.join(l for l in str if l not in punct)\n",
    "    # remove dashes that are not intra-word\n",
    "    str = my_regex.sub(lambda x: (x.group(1) if x.group(1) else ' '), str)\n",
    "    # strip extra white space\n",
    "    str = re.sub(' +',' ',str)\n",
    "    # strip leading and trailing white space\n",
    "    str = str.strip()\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #### NLP BASICS ####\n",
    "        names = X['name'].tolist()\n",
    "        cleaned_project_names = []\n",
    "        \n",
    "        for idx, doc in enumerate(names):\n",
    "            # clean\n",
    "            doc = clean_string(doc, punct, my_regex, to_lower=True)\n",
    "            # tokenize (split based on whitespace)\n",
    "            tokens = doc.split(' ')\n",
    "            # remove digits\n",
    "            tokens = [''.join([elt for elt in token if not elt.isdigit()]) for token in tokens]\n",
    "            # remove tokens shorter than 3 characters in size\n",
    "            tokens = [token for token in tokens if len(token) > 1]\n",
    "            # remove tokens exceeding 25 characters in size\n",
    "            tokens = [token for token in tokens if len(token) <= 25]\n",
    "            cleaned_project_names.append(tokens)\n",
    "            \n",
    "        ##### Word2vect embedding\n",
    "        self.model = Word2Vec(cleaned_project_names, min_count=1, size=100, workers=8)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        \n",
    "        #### SIMPLE TRANSFORMATION #### \n",
    "        \n",
    "        data['launched_date'] = pd.to_datetime(data['launched'], format='%Y-%m-%d %H:%M:%S')\n",
    "        data['deadline_date'] = pd.to_datetime(data['deadline'], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Length of project\n",
    "        data['length'] = data['deadline_date'] - data['launched_date']\n",
    "        data['length'] = [d.days for d in data['length']]\n",
    "        \n",
    "        # Features with month and year of launch\n",
    "        data['year'] = [d.year for d in data['launched_date']]\n",
    "        data['month'] = [d.month for d in data['launched_date']]\n",
    "        data['day'] = [d.day for d in data['launched_date']]\n",
    "        \n",
    "        # Length of name\n",
    "        data['name_length'] = [len(name) for name in data['name']]\n",
    "\n",
    "        # Number of words\n",
    "        data['word_number'] = [len(name.split(' ')) for name in data['name']]\n",
    "\n",
    "        # Ponctuation\n",
    "        data['question'] = (data.name.str[-1] == '?').astype(int)\n",
    "        data['exclamation'] = (data.name.str[-1] == '!').astype(int)\n",
    "\n",
    "        # Upper\n",
    "        data['uppercase'] = data.name.str.isupper().astype(float)\n",
    "        \n",
    "        # Create dummies for categorical features\n",
    "        main_category = pd.get_dummies(data['main_category'],prefix='mc')\n",
    "        category = pd.get_dummies(data['category'], prefix = 'cat')\n",
    "        country = pd.get_dummies(data['country'], prefix = 'country')\n",
    "        currency = pd.get_dummies(data['currency'], prefix = 'currency')\n",
    "\n",
    "        data = pd.concat([data, main_category, category, country, currency], axis=1)\n",
    "        \n",
    "        # Drop several features\n",
    "        names = data['name'].tolist()\n",
    "\n",
    "        features_to_drop =['main_category', 'category', 'country', 'currency', 'name',\n",
    "                           'deadline', 'deadline_date', 'launched_date', 'launched',\n",
    "                           'usd_goal_real', 'ID']\n",
    "        data.drop(features_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        #### NLP BASICS ####\n",
    "        cleaned_project_names = []\n",
    "        \n",
    "        for idx, doc in enumerate(names):\n",
    "            # clean\n",
    "            doc = clean_string(doc, punct, my_regex, to_lower=True)\n",
    "            # tokenize (split based on whitespace)\n",
    "            tokens = doc.split(' ')\n",
    "            # remove digits\n",
    "            tokens = [''.join([elt for elt in token if not elt.isdigit()]) for token in tokens]\n",
    "            # remove tokens shorter than 3 characters in size\n",
    "            tokens = [token for token in tokens if len(token) > 1]\n",
    "            # remove tokens exceeding 25 characters in size\n",
    "            tokens = [token for token in tokens if len(token) <= 25]\n",
    "            cleaned_project_names.append(tokens)\n",
    "            \n",
    "        name_matrix = np.zeros((len(cleaned_project_names), 100), dtype=\"float32\")\n",
    "\n",
    "        for i in range(len(cleaned_project_names)):\n",
    "            try:\n",
    "                name_matrix[i,]= self.model.wv[cleaned_project_names[i]].sum(0) / len(cleaned_project_names[i]) \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        name_embeddings = pd.DataFrame(name_matrix)\n",
    "        \n",
    "        data = pd.concat([data, name_embeddings], axis=1)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = LGBMRegressor()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        prediction = self.model.predict(X)\n",
    "        return np.maximum(prediction, np.zeros(prediction.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "feature_extractor.fit(X_train, y_train)\n",
    "\n",
    "X_train = feature_extractor.transform(X_train)\n",
    "X_test = feature_extractor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_regressor = Regressor()\n",
    "\n",
    "lgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgb_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- REGRESSION METRICS --------\n",
      "\n",
      "RMSE: 78447.00\n",
      "MAE: 13146.39\n",
      "\n",
      "-------- CLASSIFICATION METRICS --------\n",
      "\n",
      "Accuracy: 0.65\n",
      "Precision: 0.49\n",
      "Recall: 0.39\n"
     ]
    }
   ],
   "source": [
    "metric_report(X_test, y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
